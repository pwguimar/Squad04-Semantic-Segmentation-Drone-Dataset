{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luanaxcardoso/Squad04-Semantic-Segmentation-Drone-Dataset/blob/main/Sq04_atividade01_062025.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelo de Segmenta√ß√£o de Imagens Urbanas\n",
        "## Bootcamp Machine Learning - Atl√¢ntico Avanti: 06/2025.\n",
        "\n",
        "Neste primeira etapa, o trabalho avaliou o dataset \"Semantic Segmentation Drone Dataset\" e teve como foco principal a an√°lise explorat√≥ria dos dados dispon√≠veis.\n",
        "\n",
        "**Objetivo**: apresentar informa√ß√µes iniciais sobre as caracter√≠sticas do dataset.\n",
        "\n",
        "**Integrantes**:\n",
        "\n",
        "- Felipe Ferreira Dos Santos\n",
        "- Luana Aparecida Cardoso\n",
        "- Hozana Izadora Da Silva Ferreira\n",
        "- Patrick Wohrle Guimaraes\n",
        "- Sarah Cavalcante Salvino\n",
        "\n",
        "**Dataset dispon√≠vel em**: [Kaggle]( https://www.kaggle.com/datasets/santurini/semantic-segmentation-drone-dataset?select=Image)"
      ],
      "metadata": {
        "id": "4KDKkJhuqPDO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìö Instala√ß√µes, montar drive (Gdrive), importar Bibliotecas e  leitura dataset"
      ],
      "metadata": {
        "id": "f-KEQy0wq0J1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instala√ß√£o de bibliotecas necess√°rias\n",
        "!pip install pandas numpy matplotlib Pillow opencv-python imagehash tqdm tabulate"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wovo0oJmsJl0",
        "outputId": "e2e86167-dd9a-4937-cc4c-99cbd3cee8fc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: imagehash in /usr/local/lib/python3.11/dist-packages (4.3.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (0.9.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: PyWavelets in /usr/local/lib/python3.11/dist-packages (from imagehash) (1.8.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from imagehash) (1.15.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Montar o Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "-drNDexiq4FS",
        "outputId": "6be3305b-01a4-4d06-f7ae-2a494f6d6de6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import imagehash\n",
        "import ast\n",
        "import json\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "from tabulate import tabulate\n",
        "from pathlib import Path\n",
        "from itertools import combinations\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "# Defini√ß√£o dos caminhos para o dataset no Google Drive\n",
        "# AJUSTE ESTES CAMINHOS para onde voc√™ salvou o dataset no SEU Google Drive\n",
        "# Exemplo: se voc√™ salvou o conte√∫do da pasta 'semantic-segmentation-drone-dataset'\n",
        "# dentro de 'Meu Drive/datasets/semantic-segmentation-drone-dataset'\n",
        "BASE_DIR = \"/content/drive/MyDrive/dataset\"\n",
        "IMAGE_DIR = os.path.join(BASE_DIR, \"binary_dataset/binary_dataset/original_images/\")\n",
        "MASK_DIR = os.path.join(BASE_DIR, \"binary_dataset/binary_dataset/images_semantic/\")\n",
        "\n",
        "# Verificar se os diret√≥rios existem\n",
        "if not os.path.exists(IMAGE_DIR):\n",
        "    print(f\"ERRO: Diret√≥rio de imagens n√£o encontrado em {IMAGE_DIR}\")\n",
        "    print(\"Por favor, ajuste o caminho IMAGE_DIR para o local correto no seu Google Drive.\")\n",
        "if not os.path.exists(MASK_DIR):\n",
        "    print(f\"ERRO: Diret√≥rio de m√°scaras n√£o encontrado em {MASK_DIR}\")\n",
        "    print(\"Por favor, ajuste o caminho MASK_DIR para o local correto no seu Google Drive.\")\n",
        "\n",
        "# Lista de arquivos nos diret√≥rios\n",
        "# Use um bloco try-except caso os diret√≥rios n√£o existam (devido a caminhos incorretos)\n",
        "try:\n",
        "    image_files = sorted([f for f in os.listdir(IMAGE_DIR) if os.path.isfile(os.path.join(IMAGE_DIR, f))])\n",
        "    mask_files = sorted([f for f in os.listdir(MASK_DIR) if os.path.isfile(os.path.join(MASK_DIR, f))])\n",
        "\n",
        "    print(f\"Total de imagens encontradas: {len(image_files)}\")\n",
        "    print(f\"Total de m√°scaras encontradas: {len(mask_files)}\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(\"\\nN√£o foi poss√≠vel listar os arquivos. Verifique se os caminhos IMAGE_DIR e MASK_DIR est√£o corretos.\")\n",
        "    image_files = [] # Definir como lista vazia para evitar erros nos pr√≥ximos passos\n",
        "    mask_files = []"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2G7hl3Br-sI",
        "outputId": "234eb638-a59b-4ced-f8c5-b0f0594822db"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de imagens encontradas: 400\n",
            "Total de m√°scaras encontradas: 400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Integridade dos Arquivos"
      ],
      "metadata": {
        "id": "x5r__Wd0zEkU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import os\n",
        "\n",
        "# Montar o Google Drive (execute esta c√©lula no Colab antes de rodar o resto)\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "\n",
        "# Defina os caminhos com base no seu Google Drive\n",
        "#BASE_DIR = \"/content/drive/MyDrive/dataset\" # This is correct, points to MyDrive/dataset\n",
        "\n",
        "# Corre√ß√£o aqui: remova o \"dataset/\" extra\n",
        "#IMAGE_DIR = os.path.join(BASE_DIR, \"original_images/\")\n",
        "#MASK_DIR = os.path.join(BASE_DIR, \"images_semantic/\")\n",
        "#IMAGE_DIR = os.path.join(BASE_DIR, \"binary_dataset/binary_dataset/original_images/\")\n",
        "#MASK_DIR = os.path.join(BASE_DIR, \"binary_dataset/binary_dataset/images_semantic/\")\n",
        "\n",
        "# Esta fun√ß√£o verifica:\n",
        "# 1. Se os arquivos das duas pastas t√™m o mesmo formato (ex: .png)\n",
        "# 2. Se os arquivos t√™m os mesmos nomes (ignorando a extens√£o)\n",
        "def verificar_imagens(original_dir, semantic_dir):\n",
        "    resultados = []\n",
        "\n",
        "    def obter_info_diretorio(pasta):\n",
        "        # Listar apenas arquivos, ignorando subdiret√≥rios\n",
        "        arquivos = [f for f in os.listdir(pasta) if os.path.isfile(os.path.join(pasta, f))]\n",
        "        extensoes = {os.path.splitext(f)[-1].lower() for f in arquivos}\n",
        "        nomes_base = {os.path.splitext(f)[0] for f in arquivos}\n",
        "        return arquivos, extensoes, nomes_base\n",
        "\n",
        "    try:\n",
        "        arquivos_ori, ext_ori, nomes_ori = obter_info_diretorio(original_dir)\n",
        "        arquivos_sem, ext_sem, nomes_sem = obter_info_diretorio(semantic_dir)\n",
        "    except FileNotFoundError as e:\n",
        "        return [f\"‚ùå Erro ao acessar as pastas: {e}\"]\n",
        "    except Exception as e: # Catch other potential errors during listing\n",
        "        return [f\"‚ùå Ocorreu um erro inesperado ao processar os diret√≥rios: {e}\"]\n",
        "\n",
        "\n",
        "    if len(ext_ori) == 1:\n",
        "        resultados.append(f\"‚úÖ original_images: todas as imagens est√£o no formato {list(ext_ori)[0]}\")\n",
        "    else:\n",
        "        resultados.append(\"‚ö†Ô∏è original_images cont√©m m√∫ltiplos formatos:\")\n",
        "        resultados.extend([f\"   - {ext}\" for ext in sorted(ext_ori)])\n",
        "\n",
        "    if len(ext_sem) == 1:\n",
        "        resultados.append(f\"‚úÖ images_semantic: todas as imagens est√£o no formato {list(ext_sem)[0]}\")\n",
        "    else:\n",
        "        resultados.append(\"‚ö†Ô∏è images_semantic cont√©m m√∫ltiplos formatos:\")\n",
        "        resultados.extend([f\"   - {ext}\" for ext in sorted(ext_sem)])\n",
        "\n",
        "    if nomes_ori == nomes_sem:\n",
        "        resultados.append(\"‚úÖ As duas pastas possuem os mesmos nomes de arquivos (sem extens√£o).\")\n",
        "    else:\n",
        "        # Sort these sets to ensure consistent output order\n",
        "        faltando_em_sem = sorted(nomes_ori - nomes_sem)\n",
        "        faltando_em_ori = sorted(nomes_sem - nomes_ori)\n",
        "\n",
        "        resultados.append(\"‚ö†Ô∏è Diferen√ßas entre os nomes de arquivos encontrados:\")\n",
        "        if faltando_em_sem:\n",
        "            resultados.append(\"   - Presentes em original_images, mas faltando em images_semantic:\")\n",
        "            resultados.extend([f\"     - {nome}\" for nome in faltando_em_sem])\n",
        "        if faltando_em_ori:\n",
        "            resultados.append(\"   - Presentes em images_semantic, mas faltando em original_images:\")\n",
        "            resultados.extend([f\"     - {nome}\" for nome in faltando_em_ori])\n",
        "\n",
        "    return resultados\n",
        "\n",
        "# Executa a verifica√ß√£o e imprime os resultados\n",
        "print(\"\\nüìã Resultados da verifica√ß√£o:\\n\")\n",
        "for linha in verificar_imagens(IMAGE_DIR, MASK_DIR):\n",
        "    print(linha)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OO-bkJmVjbRR",
        "outputId": "8168c0d7-f04a-4d6f-b389-94e8279b81f7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìã Resultados da verifica√ß√£o:\n",
            "\n",
            "‚úÖ original_images: todas as imagens est√£o no formato .png\n",
            "‚úÖ images_semantic: todas as imagens est√£o no formato .png\n",
            "‚úÖ As duas pastas possuem os mesmos nomes de arquivos (sem extens√£o).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Consist√™ncia dos Metadados**"
      ],
      "metadata": {
        "id": "6MRexX54Kijh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Verifique se h√° valores ausentes nos metadados e como esses casos s√£o tratados.**\n",
        "\n",
        "* **Verifique valores inconsistentes, por exemplo: dimens√µes de imagens fora do esperado**\n"
      ],
      "metadata": {
        "id": "K7WOxCInKwsJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "CSV_PATH = r\"/content/metadata_binario.csv\"\n",
        "VALORES_INVALIDOS = {\"\", \"N/A\", \"None\", \"[]\", \"{}\", \"nan\", \"NaN\", \"n/a\", \"null\"}\n",
        "\n",
        "CLASSES_BINARIAS = {\n",
        "    0: {0, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20},  # background\n",
        "    1: {1, 2, 3, 4, 9}  # objeto\n",
        "}\n",
        "\n",
        "# Fun√ß√£o para formatar porcentagens de acordo com as faixas de pixels\n",
        "# de background e objeto\n",
        "def formatar_porcentagem(valor):\n",
        "    if valor == 0:\n",
        "        return \"0%\"\n",
        "    elif valor < 0.01:\n",
        "        return \"<1%\"\n",
        "    elif valor < 0.1:\n",
        "        return \"1-10%\"\n",
        "    elif valor < 0.25:\n",
        "        return \"10-25%\"\n",
        "    elif valor < 0.5:\n",
        "        return \"25-50%\"\n",
        "    elif valor < 0.75:\n",
        "        return \"50-75%\"\n",
        "    else:\n",
        "        return \">75%\"\n",
        "\n",
        "def verificar_metadados(csv_path):\n",
        "    if not os.path.exists(csv_path):\n",
        "        print(f\"[ERRO] Arquivo n√£o encontrado: {csv_path}\")\n",
        "        return\n",
        "\n",
        "    df = pd.read_csv(csv_path)\n",
        "    total_imagens = len(df)\n",
        "    print(f\"\\n‚ÑπÔ∏è Total de imagens no dataset: {total_imagens:,}\")\n",
        "\n",
        "    print(\"\\n 1. Valores ausentes ou inv√°lidos:\")\n",
        "    print(\"-\" * 50)\n",
        "    nulos = df.isnull().sum()\n",
        "    nulos = nulos[nulos > 0]\n",
        "\n",
        "    if nulos.empty:\n",
        "        print(\" Nenhum valor ausente (NaN) encontrado.\")\n",
        "    else:\n",
        "        print(\" Valores ausentes encontrados:\")\n",
        "        print(tabulate(nulos.reset_index().rename(columns={\"index\": \"Coluna\", 0: \"Total NaN\"}), headers=\"keys\", tablefmt=\"pretty\"))\n",
        "\n",
        "    simbolicos_invalidos = []\n",
        "    for col in df.columns:\n",
        "        count = df[col].astype(str).isin(VALORES_INVALIDOS).sum()\n",
        "        if count > 0:\n",
        "            simbolicos_invalidos.append((col, count))\n",
        "\n",
        "    if not simbolicos_invalidos:\n",
        "        print(\" Nenhum valor simb√≥lico inv√°lido encontrado.\")\n",
        "    else:\n",
        "        print(\"\\n Valores simb√≥licos inv√°lidos encontrados:\")\n",
        "        print(tabulate(simbolicos_invalidos, headers=[\"Coluna\", \"Quantidade\"], tablefmt=\"pretty\"))\n",
        "\n",
        "    print(\"\\n 2. Dimens√µes das imagens:\")\n",
        "    print(\"-\" * 50)\n",
        "    retangulares = df[df[\"largura\"] != df[\"altura\"]]\n",
        "    if retangulares.empty:\n",
        "        print(\" Todas as imagens s√£o quadradas (largura = altura).\")\n",
        "    else:\n",
        "        primeiro = retangulares.iloc[0]\n",
        "        print(f\"  {len(retangulares)} imagens retangulares encontradas.\")\n",
        "        print(f\"  Exemplo: arquivo={primeiro['arquivo']}, largura={primeiro['largura']}, altura={primeiro['altura']}\")\n",
        "\n",
        "\n",
        "    print(\"\\n 3. Consist√™ncia dos dados de pixels:\")\n",
        "    print(\"-\" * 50)\n",
        "    df[\"soma_pixels\"] = df[\"pixels_background\"] + df[\"pixels_objeto\"]\n",
        "    inconsistencias = df[df[\"soma_pixels\"] != df[\"total_pixels\"]]\n",
        "\n",
        "    if inconsistencias.empty:\n",
        "        print(\" Todas as imagens t√™m soma de pixels (background + objeto) igual ao total.\")\n",
        "    else:\n",
        "        print(f\" {len(inconsistencias)} imagens com soma de pixels inconsistente:\")\n",
        "        print(tabulate(inconsistencias[[\"arquivo\", \"pixels_background\", \"pixels_objeto\", \"total_pixels\"]].head(), headers=\"keys\", tablefmt=\"pretty\"))\n",
        "\n",
        "    df[\"soma_proporcao\"] = df[\"proporcao_background\"] + df[\"proporcao_objeto\"]\n",
        "    proporcoes_inconsistentes = df[abs(df[\"soma_proporcao\"] - 1.0) > 0.01]\n",
        "    if proporcoes_inconsistentes.empty:\n",
        "        print(\" Todas as imagens t√™m propor√ß√µes que somam aproximadamente 1.0.\")\n",
        "    else:\n",
        "        print(f\" {len(proporcoes_inconsistentes)} imagens com propor√ß√µes inconsistentes:\")\n",
        "        print(tabulate(proporcoes_inconsistentes[[\"arquivo\", \"proporcao_background\", \"proporcao_objeto\", \"soma_proporcao\"]].head(), headers=\"keys\", tablefmt=\"pretty\"))\n",
        "\n",
        "    print(\"\\n 4. Verifica√ß√£o das faixas de porcentagem:\")\n",
        "    print(\"-\" * 50)\n",
        "    df[\"faixa_calculada\"] = df[\"proporcao_objeto\"].apply(formatar_porcentagem)\n",
        "    faixas_incorretas = df[df[\"faixa_proporcao_objeto\"] != df[\"faixa_calculada\"]]\n",
        "    if faixas_incorretas.empty:\n",
        "        print(\" Todas as faixas de porcentagem est√£o corretamente calculadas.\")\n",
        "    else:\n",
        "        print(f\" {len(faixas_incorretas)} imagens com faixas de porcentagem incorretas:\")\n",
        "        print(tabulate(faixas_incorretas[[\"arquivo\", \"proporcao_objeto\", \"faixa_proporcao_objeto\", \"faixa_calculada\"]].head(), headers=\"keys\", tablefmt=\"pretty\"))\n",
        "\n",
        "        # 5. An√°lise bin√°ria: presen√ßa de fundo e objeto\n",
        "    print(\"\\n 5. An√°lise bin√°ria (com base em background e objeto):\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    if {\"somente_background\", \"somente_objeto\", \"background_e_objeto\"}.issubset(df.columns):\n",
        "        total = len(df)\n",
        "        apenas_bg = df[\"somente_background\"].sum()\n",
        "        apenas_obj = df[\"somente_objeto\"].sum()\n",
        "        ambos = df[\"background_e_objeto\"].sum()\n",
        "\n",
        "        print(f\" Imagens com apenas background: {apenas_bg} ({apenas_bg / total:.1%})\")\n",
        "        print(f\" Imagens com apenas objeto: {apenas_obj} ({apenas_obj / total:.1%})\")\n",
        "        print(f\" Imagens com background e objeto: {ambos} ({ambos / total:.1%})\")\n",
        "\n",
        "        if apenas_bg > 0:\n",
        "            print(\"  Algumas imagens n√£o t√™m nenhum pixel de objeto ‚Äî podem ser irrelevantes para o modelo.\")\n",
        "        if apenas_obj > 0:\n",
        "            print(\"  Algumas imagens t√™m apenas objeto ‚Äî verifique se o fundo foi corretamente identificado como classe 0.\")\n",
        "    else:\n",
        "        print(\" As colunas 'somente_background', 'somente_objeto', 'background_e_objeto' n√£o est√£o presentes no CSV.\")\n",
        "        print(\"Sem elas, n√£o √© poss√≠vel avaliar a presen√ßa dos grupos bin√°rios nas m√°scaras.\")\n",
        "\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\" RESUMO FINAL DA QUALIDADE DOS METADADOS\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    problemas = []\n",
        "    if not nulos.empty:\n",
        "        problemas.append(f\"‚Ä¢ Valores ausentes (NaN) em {len(nulos)} coluna(s)\")\n",
        "    if simbolicos_invalidos:\n",
        "        problemas.append(f\"‚Ä¢ Valores simb√≥licos inv√°lidos em {len(simbolicos_invalidos)} coluna(s)\")\n",
        "    if not retangulares.empty:\n",
        "        problemas.append(f\"‚Ä¢ {len(retangulares)} imagens retangulares (largura ‚â† altura)\")\n",
        "    if not inconsistencias.empty:\n",
        "        problemas.append(f\"‚Ä¢ {len(inconsistencias)} imagens com soma de pixels inconsistente\")\n",
        "    if not proporcoes_inconsistentes.empty:\n",
        "        problemas.append(f\"‚Ä¢ {len(proporcoes_inconsistentes)} imagens com propor√ß√µes inconsistentes\")\n",
        "    if not faixas_incorretas.empty:\n",
        "        problemas.append(f\"‚Ä¢ {len(faixas_incorretas)} imagens com faixas de porcentagem incorretas\")\n",
        "    if 'classes_presentes' in df.columns and classes_nao_mapeadas:\n",
        "        problemas.append(f\"‚Ä¢ {len(classes_nao_mapeadas)} classe(s) n√£o mapeadas no agrupamento bin√°rio\")\n",
        "\n",
        "    if problemas:\n",
        "        print(\"\\n PROBLEMAS ENCONTRADOS:\")\n",
        "        for problema in problemas:\n",
        "            print(problema)\n",
        "    else:\n",
        "        print(\"\\n METADADOS CONSISTENTES: Nenhum problema grave encontrado!\")\n",
        "        print(\"O dataset parece estar bem preparado para uso em modelos de segmenta√ß√£o sem√¢ntica.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    verificar_metadados(CSV_PATH)\n",
        "\n"
      ],
      "metadata": {
        "id": "-sn7aFfdK__Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cdc4b4a-3018-4798-a6a0-12a054611d24"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚ÑπÔ∏è Total de imagens no dataset: 400\n",
            "\n",
            " 1. Valores ausentes ou inv√°lidos:\n",
            "--------------------------------------------------\n",
            " Nenhum valor ausente (NaN) encontrado.\n",
            " Nenhum valor simb√≥lico inv√°lido encontrado.\n",
            "\n",
            " 2. Dimens√µes das imagens:\n",
            "--------------------------------------------------\n",
            "  400 imagens retangulares encontradas.\n",
            "  Exemplo: arquivo=000.png, largura=960, altura=736\n",
            "\n",
            " 3. Consist√™ncia dos dados de pixels:\n",
            "--------------------------------------------------\n",
            " Todas as imagens t√™m soma de pixels (background + objeto) igual ao total.\n",
            " Todas as imagens t√™m propor√ß√µes que somam aproximadamente 1.0.\n",
            "\n",
            " 4. Verifica√ß√£o das faixas de porcentagem:\n",
            "--------------------------------------------------\n",
            " Todas as faixas de porcentagem est√£o corretamente calculadas.\n",
            "\n",
            " 5. An√°lise bin√°ria (com base em background e objeto):\n",
            "--------------------------------------------------\n",
            " Imagens com apenas background: 0 (0.0%)\n",
            " Imagens com apenas objeto: 0 (0.0%)\n",
            " Imagens com background e objeto: 400 (100.0%)\n",
            "\n",
            "============================================================\n",
            " RESUMO FINAL DA QUALIDADE DOS METADADOS\n",
            "============================================================\n",
            "\n",
            " PROBLEMAS ENCONTRADOS:\n",
            "‚Ä¢ 400 imagens retangulares (largura ‚â† altura)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Embora os metadados estejam √≠ntegros e sem valores ausentes, sem erros de soma de pixels ou de propor√ß√µes e com todas as faixas corretamente calculadas, h√° um ponto cr√≠tico: todas as 400 imagens s√£o retangulares (960 √ó 736 no exemplo).\n",
        "\n",
        "E idealmente dever√≠amos trabalhar com formatos quadrados para manter a propor√ß√£o dos pixels em tarefas de segmenta√ß√£o sem√¢ntica.\n",
        "\n",
        "Esse desvio pode afetar a performance de modelos que esperam entradas quadradas, portanto, uma solu√ß√£o seria redimensionar ou recortar as m√°scaras para um formato uniforme."
      ],
      "metadata": {
        "id": "wGnsfJkTo98K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Ud6TyNiGMFBq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Qualidade das Imagens (Identificar Imagens Corrompidas)\n",
        "- Objetivo: Identificar imagens (e m√°scaras) que n√£o podem ser abertas ou processadas, indicando corrup√ß√£o."
      ],
      "metadata": {
        "id": "39FLL3Sj_SM_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "# Removida a importa√ß√£o de tqdm\n",
        "\n",
        "def check_corrupted_files(directory, filenames, file_type):\n",
        "    \"\"\"\n",
        "    Verifica se os arquivos em um diret√≥rio espec√≠fico est√£o corrompidos\n",
        "    tentando abri-los e verificando sua integridade usando Pillow.\n",
        "\n",
        "    Args:\n",
        "        directory (str): O caminho para o diret√≥rio contendo os arquivos.\n",
        "        filenames (list): Uma lista de nomes de arquivos a serem verificados.\n",
        "        file_type (str): Um nome descritivo para o tipo de arquivo (ex: 'imagens', 'm√°scaras').\n",
        "\n",
        "    Returns:\n",
        "        list: Uma lista de tuplas, onde cada tupla cont√©m o nome do arquivo\n",
        "              corrompido e a mensagem de erro capturada.\n",
        "    \"\"\"\n",
        "    corrupted_list = []\n",
        "    print(f\"\\nVerificando {file_type} corrompidas...\")\n",
        "\n",
        "    total_files = len(filenames)\n",
        "    if total_files == 0:\n",
        "        print(f\"Nenhum arquivo {file_type} encontrado para verificar.\")\n",
        "        return []\n",
        "\n",
        "    # Define um intervalo para imprimir o progresso (ex: a cada 10% ou 50 arquivos)\n",
        "    # Garante que o intervalo seja pelo menos 1\n",
        "    print_interval = max(1, min(total_files // 10, 50))\n",
        "\n",
        "    for i, filename in enumerate(filenames):\n",
        "        filepath = os.path.join(directory, filename)\n",
        "\n",
        "        # Imprime uma mensagem de progresso em intervalos definidos\n",
        "        if (i + 1) % print_interval == 0 or (i + 1) == total_files:\n",
        "            print(f\"  Processados {i + 1}/{total_files} arquivos {file_type}...\")\n",
        "\n",
        "        try:\n",
        "            # Abre a imagem e verifica sua integridade sem carregar todos os dados\n",
        "            with Image.open(filepath) as img:\n",
        "                img.verify()\n",
        "        except Exception as e:\n",
        "            # Captura qualquer erro durante a abertura ou verifica√ß√£o\n",
        "            corrupted_list.append((filename, str(e)))\n",
        "\n",
        "    print(f\"Verifica√ß√£o de {file_type} completa.\")\n",
        "\n",
        "    return corrupted_list\n",
        "\n",
        "# --- In√≠cio do Algoritmo Principal ---\n",
        "# Assume que 'image_files' e 'mask_files' s√£o listas de nomes de arquivos\n",
        "# e 'IMAGE_DIR' e 'MASK_DIR' s√£o os caminhos para os diret√≥rios,\n",
        "# definidos ANTES deste bloco.\n",
        "\n",
        "if 'image_files' in locals() and 'mask_files' in locals() and image_files and mask_files:\n",
        "    # Chama a fun√ß√£o para verificar imagens e m√°scaras\n",
        "    corrupted_images = check_corrupted_files(IMAGE_DIR, image_files, 'imagens')\n",
        "    corrupted_masks = check_corrupted_files(MASK_DIR, mask_files, 'm√°scaras')\n",
        "\n",
        "    # --- Relat√≥rio dos Resultados ---\n",
        "    if not corrupted_images:\n",
        "        print(\"Verifica√ß√£o de Qualidade: Nenhuma imagem corrompida encontrada.\")\n",
        "    else:\n",
        "        print(f\"Verifica√ß√£o de Qualidade: {len(corrupted_images)} imagens corrompidas encontradas.\")\n",
        "        # Exemplo de como imprimir os arquivos corrompidos (opcional)\n",
        "        # print(\" Exemplos (arquivo, erro):\")\n",
        "        # for item in corrupted_images[:10]:\n",
        "        #     print(f\"  {item[0]}: {item[1]}\")\n",
        "\n",
        "    if not corrupted_masks:\n",
        "        print(\"Verifica√ß√£o de Qualidade: Nenhuma m√°scara corrompida encontrada.\")\n",
        "    else:\n",
        "        print(f\"Verifica√ß√£o de Qualidade: {len(corrupted_masks)} m√°scaras corrompidas encontradas.\")\n",
        "        # Exemplo de como imprimir os arquivos corrompidos (opcional)\n",
        "        # print(\" Exemplos (arquivo, erro):\")\n",
        "        # for item in corrupted_masks[:10]:\n",
        "        #     print(f\"  {item[0]}: {item[1]}\")\n",
        "else:\n",
        "    # Executado se as listas de arquivos estiverem vazias ou n√£o definidas\n",
        "    print(\"\\nPulando Verifica√ß√£o de Qualidade: Listas de arquivos de imagem/m√°scara vazias ou n√£o definidas.\")\n",
        "    print(\"Verifique se IMAGE_DIR e MASK_DIR est√£o definidos corretamente e cont√™m arquivos.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5rH2XI8_h7Z",
        "outputId": "775573de-038b-47ca-afd9-3bb1b8913218"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Verificando imagens corrompidas...\n",
            "  Processados 40/400 arquivos imagens...\n",
            "  Processados 80/400 arquivos imagens...\n",
            "  Processados 120/400 arquivos imagens...\n",
            "  Processados 160/400 arquivos imagens...\n",
            "  Processados 200/400 arquivos imagens...\n",
            "  Processados 240/400 arquivos imagens...\n",
            "  Processados 280/400 arquivos imagens...\n",
            "  Processados 320/400 arquivos imagens...\n",
            "  Processados 360/400 arquivos imagens...\n",
            "  Processados 400/400 arquivos imagens...\n",
            "Verifica√ß√£o de imagens completa.\n",
            "\n",
            "Verificando m√°scaras corrompidas...\n",
            "  Processados 40/400 arquivos m√°scaras...\n",
            "  Processados 80/400 arquivos m√°scaras...\n",
            "  Processados 120/400 arquivos m√°scaras...\n",
            "  Processados 160/400 arquivos m√°scaras...\n",
            "  Processados 200/400 arquivos m√°scaras...\n",
            "  Processados 240/400 arquivos m√°scaras...\n",
            "  Processados 280/400 arquivos m√°scaras...\n",
            "  Processados 320/400 arquivos m√°scaras...\n",
            "  Processados 360/400 arquivos m√°scaras...\n",
            "  Processados 400/400 arquivos m√°scaras...\n",
            "Verifica√ß√£o de m√°scaras completa.\n",
            "Verifica√ß√£o de Qualidade: Nenhuma imagem corrompida encontrada.\n",
            "Verifica√ß√£o de Qualidade: Nenhuma m√°scara corrompida encontrada.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "MUz-9K3JUYh_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Duplicatas\n",
        "\n",
        "‚ñ† Identifique imagens duplicadas que possam enviesar os resultados.  \n",
        "‚ñ† Verifique duplicatas no arquivo de informa√ß√µes.\n",
        "\n"
      ],
      "metadata": {
        "id": "jej31UzkSZiW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Caminho da pasta\n",
        "caminho_pasta = Path(\"binary_dataset/binary_dataset/images_semantic/\")\n",
        "\n",
        "# Tamanho fixo para padronizar\n",
        "tamanho_padrao = (256, 256)\n",
        "\n",
        "# Carrega todas as imagens .png\n",
        "imagens = list(caminho_pasta.glob(\"*.png\"))\n",
        "imagens_dict = {}\n",
        "\n",
        "# Carrega e padroniza\n",
        "for caminho in imagens:\n",
        "    img = cv2.imread(str(caminho), cv2.IMREAD_GRAYSCALE)\n",
        "    if img is not None:\n",
        "        img_padronizada = cv2.resize(img, tamanho_padrao)\n",
        "        imagens_dict[caminho.name] = img_padronizada\n",
        "\n",
        "# Comparar pixel a pixel\n",
        "print(\" Verificando imagens exatamente iguais:\\n\")\n",
        "iguais = False\n",
        "for (nome1, img1), (nome2, img2) in combinations(imagens_dict.items(), 2):\n",
        "    if np.array_equal(img1, img2):\n",
        "        print(f\"üü• Iguais: {nome1} == {nome2}\")\n",
        "        iguais = True\n",
        "\n",
        "if not iguais:\n",
        "    print(\"‚úÖ Nenhuma imagem exatamente igual encontrada.\")"
      ],
      "metadata": {
        "id": "hFSTgZoIUE4g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b7442e7-c82f-4696-efd7-8c91b44ae39b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Verificando imagens exatamente iguais:\n",
            "\n",
            "‚úÖ Nenhuma imagem exatamente igual encontrada.\n"
          ]
        }
      ]
    }
  ]
}